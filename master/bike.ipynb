{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib as joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hour.csv\", parse_dates=[\"dteday\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the columns we don't need from X, and defining the target variables Y\n",
    "X = df.drop(columns=[\"instant\", \"cnt\", \"casual\", \"registered\"])\n",
    "y = df[\"cnt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function defines a forward fill method to fill NAs\n",
    "def ffill_missing(ser):\n",
    "    return ser.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the forward fill imputer\n",
    "ffiller = FunctionTransformer(ffill_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the weathersit data encoder\n",
    "weather_enc = make_pipeline(\n",
    "    ffiller,\n",
    "    OrdinalEncoder(\n",
    "        handle_unknown=\"use_encoded_value\", unknown_value=X[\"weathersit\"].nunique()\n",
    "    ),\n",
    ")\n",
    "weather_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ffiller, make_column_selector(dtype_include=np.number)),\n",
    "    (weather_enc, [\"weathersit\"]),\n",
    ")\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used further ahead to consider binary feature of wether the day is weekday or weekend\n",
    "def is_weekend(data):\n",
    "    return (\n",
    "        data[\"dteday\"]\n",
    "        .dt.day_name()\n",
    "        .isin([\"Saturday\", \"Sunday\"])\n",
    "        .to_frame()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to tell how many years have elapsed since the beginning of operation (began in 2011)\n",
    "def year(data):\n",
    "    # Our reference year is 2011, the beginning of the training dataset\n",
    "    return (data[\"dteday\"].dt.year - 2011).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-vulnerability",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "preprocessing = FeatureUnion([\n",
    "    (\"is_weekend\", FunctionTransformer(is_weekend)),\n",
    "    (\"year\", FunctionTransformer(year)),\n",
    "    (\"column_transform\", ct)\n",
    "])\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Pipeline([(\"preprocessing\", preprocessing), (\"model\", RandomForestRegressor())])\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X.loc[X[\"dteday\"] < \"2012-10\"], y.loc[X[\"dteday\"] < \"2012-10\"]\n",
    "X_test, y_test = X.loc[\"2012-10\" <= X[\"dteday\"]], y.loc[\"2012-10\" <= X[\"dteday\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Dump the model\n",
    "    \n",
    "joblib.dump(reg, 'bikes.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "df.loc[df[\"dteday\"] < \"2012-10\"].set_index(\"instant\")[\"cnt\"].plot(ax=ax, label=\"Train\")\n",
    "df.loc[\"2012-10\" <= df[\"dteday\"]].set_index(\"instant\")[\"cnt\"].plot(ax=ax, label=\"Test\")\n",
    "\n",
    "pd.Series(y_pred, index=df.loc[\"2012-10\" <= df[\"dteday\"], \"instant\"]).plot(ax=ax, color=\"k\", label=\"Prediction\")\n",
    "\n",
    "ax.legend(loc=2, shadow=True, facecolor=\"0.97\")\n",
    "ax.set_xlim(15100, 15500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-muslim",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(pd.DataFrame([[\n",
    "    pd.to_datetime(\"2012-11-01\"),\n",
    "    10,\n",
    "    \"Clear, Few clouds, Partly cloudy, Partly cloudy\",\n",
    "    0.3,\n",
    "    0.31,\n",
    "    0.8,\n",
    "    0.0,\n",
    "]], columns=[\n",
    "    'dteday',\n",
    "    'hr',\n",
    "    'weathersit',\n",
    "    'temp',\n",
    "    'atemp',\n",
    "    'hum',\n",
    "    'windspeed'\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
